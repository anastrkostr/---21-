{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Содержание\n",
    "\n",
    "**1. Introduction to Statistical learning**\n",
    "\n",
    "- 1.1 Work with data and EDA\n",
    "    - 1.1.1 Load data\n",
    "    - 1.1.2 Check NAs\n",
    "    - 1.1.3 Basic stats\n",
    "    - 1.1.4 Correlations\n",
    "    - 1.1.5 Scatterplot\n",
    "- 1.2 Linear regression\n",
    "    - 1.2.1 Running linear regression\n",
    "    - 1.2.2 Improving the model\n",
    "    - 1.2.3 Linear regression by hands\n",
    "- 1.3 k-Nearest Neighbors\n",
    "    - 1.3.1 Run kNN\n",
    "    - 1.3.2 Scale the data and rerun it\n",
    "    - 1.3.3 Comparison between kNN and LR\n",
    "    - 1.3.4 Fitting kNN for different k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем, как переходить к практическим частям, необходимо обсудить общий жизненный цикл модели машинного обучения. Обычно в него входят следующие этапы:\n",
    "\n",
    "- Бизнес-анализ\n",
    "- Сбор, анализ и подготовка данных\n",
    "- Моделирование\n",
    "- Оценка решения\n",
    "- Внедрение\n",
    "- Тестирование и мониторинг\n",
    "\n",
    "\n",
    "Разберем более подробно каждый этап:\n",
    "- **Бизнес-анализ** - На этом этапе необходимо вместе с заказчиком сформулировать проблемы бизнеса, которые будет решать модель. Также, требуется понять, кто участвует в проекте со стороны заказчика, кто выделяет деньги под проект, и кто принимает ключевые решения. Вдобавок необходимо узнать существуют ли готовые решения и, если да, чем они не устраивают заказчика.\n",
    "\n",
    "- **Сбор, анализ и подготовка данных** - Задача этого шага – понять слабые и сильные стороны в имеющихся данных, определить их достаточность, предложить идеи, как их использовать, и лучше понять бизнес-процессы заказчика. Требуется провести анализ всех источников данных, к которым заказчик предоставляет доступ.\n",
    "    -  **Сбор данных** — это процесс сбора информации по интересующим переменным в установленной систематической форме, которая позволяет отвечать на поставленные вопросы исследования, проверять гипотезы и оценивать результаты.\n",
    "    - **Нормализация данных** — это то место, где аналитики и инженеры данных обычно проводят большую часть своего времени: очистка и нормализация \"грязных\" данных. \n",
    "    - **Конструирование признаков**  - состоит из учета, статистической обработки и преобразования данных для выбора признаков, используемых в модели. \n",
    "    \n",
    "- **Моделирование** - На этом шаге происходит обучения модели. Обучение моделей машинного обучения происходит итерационно – пробуются различные модели, перебираются гиперпараметры, сравниваются значения выбранной метрики и выбирается лучшая комбинация.\n",
    "\n",
    "- **Оценка решения** - Результатом предшествующего этапа является построенная модель машинного обучения и найденные закономерности. На данном этапе происходит оценивание результатов проекта.\n",
    "\n",
    "- **Внедрение** - Внедрение модели машинного обучения в производство означает доступность модели для других бизнес-систем. Внедряя модель, другие системы могут отправлять ей данные и получать от модели прогнозы, которые, в свою очередь, используются в системах компании. Благодаря внедрению модели машинного обучения, компания сможет в полной мере воспользоваться созданной моделью машинного обучения. \n",
    "\n",
    "- **Тестирование и мониторинг** - На данном этапе осуществляется тестирование, мониторинг и контролирование модели. Это могут быть как и статистические тесты, так и, например, A/B тестирование."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to Statistical learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Work with data and EDA\n",
    "\n",
    "**Pandas** - это библиотека Python, предоставляющая широкие возможности для анализа данных. С ее помощью очень удобно загружать, обрабатывать и анализировать табличные данные с помощью SQL-подобных запросов. В связке с библиотеками Matplotlib и Seaborn появляется возможность удобного визуального анализа табличных данных.\n",
    "\n",
    "Основными структурами данных в Pandas являются классы Series и DataFrame. Первый из них представляет собой одномерный индексированный массив данных некоторого фиксированного типа. Второй - это двухмерная структура данных, представляющая собой таблицу, каждый столбец которой содержит данные одного типа. Можно представлять её как словарь объектов типа Series. Структура DataFrame отлично подходит для представления реальных данных: строки соответствуют признаковым описаниям отдельных объектов, а столбцы соответствуют признакам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Рассмотрим объект типа DataFrame. Создадим свой DataFrame одним из способов.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['client'] = ['cl1', 'cl2', 'cl3', 'cl1', 'cl2', 'cl2', 'cl3']\n",
    "df['year'] = [2020, 2020, 2020, 2018, 2018, 2019, 2019]\n",
    "df['avg_salary'] = [80000, 60000, 70000, 60000, 40000, 50000, 60000]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Раз pandas поддерживает sql - подобные запросы, то давайте сделаем один из них: выбере всех клиентов, у которых средняя годовая зарплата в 2020 больше 60000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['year'] == 2020)&(df['avg_salary'] > 60000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тоже самое можно сделать и с помощью обычного синтаксиса sql с помощью библиотеки pandasql:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandasql as ps\n",
    "\n",
    "ps.sqldf(\n",
    "    '''\n",
    "    SELECT *\n",
    "    FROM df\n",
    "    WHERE year = 2020 AND avg_salary > 60000\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также pandas поддерживает простейшие графики, например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_salary'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.1 Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем случае pandas является удобной библиотекой для табличных данных.\n",
    "Данные мы загружаем с помощью функции read_csv() библиотеки pandas. Они записаны в файле StateFarm.csv.\n",
    "Разберем основные параметры функции read_csv():\n",
    "\n",
    "```python\n",
    "pandas.read_csv(\n",
    "    filepath_or_buffer, # задает путь к файлу\n",
    "    sep=',', # задает символ - разделитель полей\n",
    "    delimeter=',', # задает символ - разделитель полей\n",
    "    header='infer', # задает номер строки, содержащей имена столбцов \n",
    "    names=None, # Задает список с именами столбцов\n",
    "    index_col=None, # задает столбец, значения которого будут использоваться в качестве меток строк датафрейма\n",
    "    usecols=None, # Задает подмножество столбцов\n",
    "    squeeze=False, # Если спарсенные данные содержат лишь один столбец, возвращает объект Series\n",
    "    decimal='.', # задает символ - десятичный разделитель (по умолчанию .)\n",
    "    encoding=None # задает тип кодировки\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте загрузим данные из файла и начнем их анализировать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./data/Auto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Смотрим на первые 5 строк\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Смотрим на последние 5 строк\n",
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на кол-во строк и столбцов\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.2 Check NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка заполненности ячеек\n",
    "print('Всего записей: ', df1.shape[0])\n",
    "df1.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Давайте выведем строки с пропущенными значениями horsepower\n",
    "df1[df1['horsepower'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.3 Basic stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Краткая статистика – info и describe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.4 Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Известно, что некоторые модели, например линейные, плохо работают с линейно зависимыми признаками. Из-за этого модель становится нестабильной и может работать неверно. Для того, чтобы увидеть такие зависимости, можно построить корреляционную матрицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "ax = sns.heatmap(df1.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.5 Scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простой график рассеяния двух признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.plot.scatter('weight', 'mpg', grid=True, title='Scatter plot of mpg and weight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод **scatter_matrix** позволяет визуализировать попарные зависимости между признаками (а также распределение каждого признака на диагонали). Проделаем это для некоторых небинарных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(\n",
    "    df1[[\"weight\", \"mpg\", \"displacement\", \"acceleration\"]], figsize=(15, 15), diagonal=\"kde\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8));\n",
    "ax = sns.pairplot(df1, plot_kws=dict(linewidth=0, s=3));\n",
    "ax.fig.suptitle(\"Pairplot of variables in Auto dataset\", y=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы перейдем к построению моделей машинного обучения. Перед тем, как разбираться и строить одну из самых известных, давайте повторим некоторые основы. \n",
    "\n",
    "Классическое, общее (и не самое формальное) определение машинного обучения звучит так:\n",
    "- говорят, что компьютерная программа обучается при решении какой-то задачи из класса T, если ее производительность, согласно метрике P, улучшается при накоплении опыта E.\n",
    "\n",
    "Далее в разных сценариях под T, P, и E подразумеваются совершенно разные вещи. Среди самых популярных задач T в машинном обучении:\n",
    "- классификация – отнесение объекта к одной из категорий на основании его признаков\n",
    "- регрессия – прогнозирование количественного признака объекта на основании прочих его признаков\n",
    "- кластеризация – разбиение множества объектов на группы на основании признаков этих объектов так, чтобы внутри групп объекты были похожи между собой, а вне одной группы – менее похожи\n",
    "- детекция аномалий – поиск объектов, \"сильно непохожих\" на все остальные в выборке либо на какую-то группу объектов\n",
    "- и много других, более специфичных. \n",
    "\n",
    "\n",
    "Под опытом E понимаются данные (без них никуда), и в зависимости от этого алгоритмы машинного обучения могут быть поделены на те, что обучаются с учителем и без учителя (supervised & unsupervised learning). \n",
    "- В задачах обучения без учителя имеется выборка, состоящая из объектов, описываемых набором признаков. \n",
    "- В задачах обучения с учителем вдобавок к этому для каждого объекта некоторой выборки, называемой обучающей, известен целевой признак – по сути это то, что хотелось бы прогнозировать для прочих объектов, не из обучающей выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда тяжело понять данное определение машинного обучения. Еще сложнее понять различия между обучением с учителем и без учителя. В рамках данной лекции мы будем рассматривать только обучение с учителем. Давайте введем неформальный пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ex = pd.DataFrame()\n",
    "train_ex['index'] = ['cl1', 'cl2', 'cl3', 'cl4', 'cl5']\n",
    "train_ex['age'] = [20, 56, 60, 21, 18]\n",
    "train_ex['income'] = [30000, 60000, 20000, 40000, 50000]\n",
    "train_ex['target'] = [0, 0, 1, 0, 1]\n",
    "\n",
    "predict_ex = pd.DataFrame()\n",
    "predict_ex['index'] = ['cl6', 'cl7', 'cl8']\n",
    "predict_ex['age'] = [33, 47, 19]\n",
    "predict_ex['income'] = [50000, 80000, 25000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим, что мы хотим построить модель, определяющую, кому можно дать кредит (клиент его вернет), а кому нельзя (не вернет). Банк работает давно, поэтому у нас есть исторические данные и реальная информация о клиентах, кто кредит вернул (target = 0), а кто не вернул (target = 1). Также предположим, что у нас есть информация о признаках клиентов - возраст и ежемесячный доход. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша задача - каким-то способом построить такую функцию от возраста и дохода, чтобы на ее выходе получить таргет. И теперь, когда придут новые клиенты, и мы бцдем знать их возраст и доход, то по нашей построенной функции мы сможем понять, кому мы сможем выдать кредит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте введем более формальные определения:\n",
    "- Объект (x) - то, для чего мы делем прогноз/анализ.\n",
    "- Ответ/целевая переменная (y) - то, что мы предсказываем.\n",
    "- X - множество объектов\n",
    "- Y - множество ответов\n",
    "- Признаки/факторы/features - характеристики объекта    \n",
    "     \n",
    "Модель(a) - это некоторая функция, которая переводит множество объектов в множество ответов.\n",
    "$a:X \\to Y$, $a \\in A$, где A - семейтво моделей.\n",
    "\n",
    "Нам необходимо в семействе моделей какого-либо типа найти самую лучшую модель. Для этого вводят функцю потерь:\n",
    "$L:Y\\times Y \\to R$\n",
    "\n",
    "- Для регрессии: $L(y,z) = (y-z)^2$\n",
    "- Для классификаци: $L(y,z) = [y \\neq z]$\n",
    "\n",
    "Далее вводят функционал ошибки (функционал - это функция от функции):\n",
    "$$Q(a, X) =  \\frac{1}{l}\\sum_{i=0}^l L(y_i, a(x_i))$$\n",
    "\n",
    "Задача машинного обучения - минимизация функционала ошибки по множеству моделей.\n",
    "$$Q(a, X)\\to \\min_{a \\in A}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теория линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод наименьших квадратов\n",
    "\n",
    "Рассказ про линейные модели мы начнем с линейной регрессии. В первую очередь, необходимо задать модель зависимости объясняемой переменной $y$ от объясняющих ее факторов, функция зависимости будет линейной: $y = w_0 + \\sum_{i=1}^m w_i x_i$. Если мы добавим фиктивную размерность $x_0 = 1$ для каждого наблюдения, тогда линейную форму можно переписать чуть более компактно, записав свободный член $w_0$ под сумму: $y = \\sum_{i=0}^m w_i x_i = \\textbf{w}^{\\text{T}} \\textbf{x}$. Если рассматривать матрицу наблюдения-признаки, у которой в строках находятся примеры из набора данных, то нам необходимо добавить единичную колонку слева. Зададим модель следующим образом:\n",
    "\n",
    "$$\\large \\textbf y = \\textbf{X} \\textbf w + \\epsilon,$$\n",
    "\n",
    "где\n",
    "- $\\textbf{y} \\in \\mathbb{R}^n$ – объясняемая (или целевая) переменная;\n",
    "- $\\textbf{w}\\in \\mathbb{R}^{m+1}$ – вектор параметров модели (в машинном обучении эти параметры часто называют весами);\n",
    "- $\\textbf{X}$ – матрица наблюдений и признаков размерности $n$ строк на $m + 1$ столбцов (включая фиктивную единичную колонку слева) с полным рангом по столбцам: $\\text{rank}\\left(\\textbf{X}\\right) = m$;\n",
    "- $\\epsilon$ – случайная переменная, соответствующая случайной, непрогнозируемой ошибке модели.\n",
    "\n",
    "Можем выписать выражение для каждого конкретного наблюдения\n",
    "\n",
    "$$\\large \n",
    "y_i = \\sum_{j=0}^m w_j X_{ij} + \\epsilon_i$$\n",
    "\n",
    "Также на модель накладываются следующие ограничения (иначе это будет какая то другая регрессия, но точно не линейная):\n",
    "- матожидание случайных ошибок равно нулю: $\\forall i: \\mathbb{E}\\left[\\epsilon_i\\right] = 0$;\n",
    "- дисперсия случайных ошибок одинакова и конечна, это свойство называется <a href=\"https://ru.wikipedia.org/wiki/%D0%93%D0%BE%D0%BC%D0%BE%D1%81%D0%BA%D0%B5%D0%B4%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%BD%D0%BE%D1%81%D1%82%D1%8C\">гомоскедастичностью</a>: $\\forall i: \\text{Var}\\left(\\epsilon_i\\right) = \\sigma^2 < \\infty$;\n",
    "- случайные ошибки не скоррелированы: $\\forall i \\neq j: \\text{Cov}\\left(\\epsilon_i, \\epsilon_j\\right) = 0$.\n",
    "\n",
    "Оценка $\\widehat{w}_i$ весов $w_i$ называется *линейной*, если\n",
    "\n",
    "$$\\large \\widehat{w}_i = \\omega_{1i}y_1 + \\omega_{2i}y_2 + \\cdots + \\omega_{1n}y_n,$$\n",
    "\n",
    "где $\\forall\\ k\\ \\omega_{ki}$ зависит только от наблюдаемых данных $\\textbf{X}$ и почти наверняка нелинейно. Так как решением задачи поиска оптимальных весов будет именно линейная оценка, то и модель называется *линейной регрессией*. Введем еще одно определение. Оценка $\\widehat{w}_i$ называется *несмещенной* тогда, когда матожидание оценки равно реальному, но неизвестному значению оцениваемого параметра:\n",
    "\n",
    "$$\\large \\mathbb{E}\\left[\\widehat{w}_i\\right] = w_i$$\n",
    "\n",
    "Один из способов вычислить значения параметров модели является <b>метод наименьших квадратов</b> (МНК), который минимизирует среднеквадратичную ошибку между реальным значением зависимой переменной и прогнозом, выданным моделью:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\\mathcal{L}\\left(\\textbf{X}, \\textbf{y}, \\textbf{w} \\right) &=& \\frac{1}{2n} \\sum_{i=1}^n \\left(y_i - \\textbf{w}^{\\text{T}} \\textbf{x}_i\\right)^2 \\\\\n",
    "&=& \\frac{1}{2n} \\left\\| \\textbf{y} - \\textbf{X} \\textbf{w} \\right\\|_2^2 \\\\\n",
    "&=& \\frac{1}{2n} \\left(\\textbf{y} - \\textbf{X} \\textbf{w}\\right)^{\\text{T}} \\left(\\textbf{y} - \\textbf{X} \\textbf{w}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Для решения данной оптимизационной задачи необходимо вычислить производные по параметрам модели, приравнять их к нулю и решить полученные уравнения относительно $\\textbf w$ (матричное дифференцирование неподготовленному читателю может показаться затруднительным, попробуйте расписать все через суммы, чтобы убедиться в ответе):\n",
    "\n",
    "Шпаргалка по матричным производным:\n",
    "\n",
    "\n",
    "$$\\large \\begin{array}{rcl} \n",
    "\\frac{\\partial}{\\partial \\textbf{X}} \\textbf{X}^{\\text{T}} \\textbf{A} &=& \\textbf{A} \\\\\n",
    "\\frac{\\partial}{\\partial \\textbf{X}} \\textbf{X}^{\\text{T}} \\textbf{A} \\textbf{X} &=& \\left(\\textbf{A} + \\textbf{A}^{\\text{T}}\\right)\\textbf{X} \\\\\n",
    "\\frac{\\partial}{\\partial \\textbf{A}} \\textbf{X}^{\\text{T}} \\textbf{A} \\textbf{y} &=&  \\textbf{X}^{\\text{T}} \\textbf{y}\\\\\n",
    "\\frac{\\partial}{\\partial \\textbf{X}} \\textbf{A}^{-1} &=& -\\textbf{A}^{-1} \\frac{\\partial \\textbf{A}}{\\partial \\textbf{X}} \\textbf{A}^{-1} \n",
    "\\end{array}$$\n",
    "\n",
    "Продолжим:\n",
    "\n",
    "$$\\Large \\begin{array}{rcl} \\frac{\\partial \\mathcal{L}}{\\partial \\textbf{w}} &=& \\frac{\\partial}{\\partial \\textbf{w}} \\frac{1}{2n} \\left( \\textbf{y}^{\\text{T}} \\textbf{y} -2\\textbf{y}^{\\text{T}} \\textbf{X} \\textbf{w} + \\textbf{w}^{\\text{T}} \\textbf{X}^{\\text{T}} \\textbf{X} \\textbf{w}\\right) \\\\\n",
    "&=& \\frac{1}{2n} \\left(-2 \\textbf{X}^{\\text{T}} \\textbf{y} + 2\\textbf{X}^{\\text{T}} \\textbf{X} \\textbf{w}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "$$\\Large \\begin{array}{rcl} \\frac{\\partial \\mathcal{L}}{\\partial \\textbf{w}} = 0 &\\Leftrightarrow& \\frac{1}{2n} \\left(-2 \\textbf{X}^{\\text{T}} \\textbf{y} + 2\\textbf{X}^{\\text{T}} \\textbf{X} \\textbf{w}\\right) = 0 \\\\\n",
    "&\\Leftrightarrow& -\\textbf{X}^{\\text{T}} \\textbf{y} + \\textbf{X}^{\\text{T}} \\textbf{X} \\textbf{w} = 0 \\\\\n",
    "&\\Leftrightarrow& \\textbf{X}^{\\text{T}} \\textbf{X} \\textbf{w} = \\textbf{X}^{\\text{T}} \\textbf{y} \\\\\n",
    "&\\Leftrightarrow& \\textbf{w} = \\left(\\textbf{X}^{\\text{T}} \\textbf{X}\\right)^{-1} \\textbf{X}^{\\text{T}} \\textbf{y}\n",
    "\\end{array}$$\n",
    "\n",
    "Итак, имея в виду все определения и условия описанные выше, мы можем утверждать, опираясь на <a href=\"https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%93%D0%B0%D1%83%D1%81%D1%81%D0%B0_%E2%80%94_%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D0%B0\">теорему Маркова-Гаусса</a>, что оценка МНК является лучшей оценкой параметров модели, среди всех <i>линейных</i> и <i>несмещенных</i> оценок, то есть обладающей наименьшей дисперсией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы разобрали теорию линейной регрессии. Но перед тем, как мы перейдем к построению модели, мы должны понять, а зачем вообще делят выборку и как с помощью такого подхода оценивают качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обязательно нужно выполнить проверку (валидацию) модели, т.е. посмотреть, как модель выдает прогнозы на данных, не участвовавших в обучении. Самый простой способ проверки — случайное разбиение на обучающую и тестовую выборки.\n",
    "\n",
    "Сначала мы случайным образом разбиваем имеющиеся данные на две выборки: обучающую и тестовую. Формирование тестовой выборки — это способ преодолеть такие несовершенства неидеального мира, как ограничения в объеме данных и ресурсов, а также невозможность получения дополнительных данных из порождающего распределения. \n",
    "\n",
    "В данном случае тестовая выборка должна представлять собой новые, еще неизвестные модели данные. Важно использовать тестовую выборку лишь однократно. Обычно 2/3 доступных данных назначают в обучающую выборку, а оставшуюся 1/3 данных - в тестовую выборку. Другими популярными методами разбиения на обучающую/тестовую выборки являются 60/40, 70/30, 80/20 или даже 90/10, если набор данных относительно велик.\n",
    "\n",
    "Затем необходимо построить на обучающей выборке (обучить) модели предварительной подготовки — модель импутации, модель стандартизации, модель дамми-кодирования и модель машинного обучения, которая, как мы предполагаем, может оказаться подходящей для решения данной задачи. Модели в библиотеке scikit-learn реализованы в виде классов.\n",
    "\n",
    "\n",
    "У любой модели есть параметры, которые мы находим в ходе обучения. Например, у нас будет класс SimpleImputer, который обучает модель предварительной подготовки — модель импутации пропущенных значений. Здесь параметрами будут статистики, которые мы используем для импутации пропусков (среднее, медиана). \n",
    "\n",
    "Например, для класса LoisticRegression, строящего модель машинного обучения — модель логистической регрессии, параметрами будут регрессионные коэффициенты для соответствующих предикторов, для класса DecisionTreeClassifier, строящего другую модель машинного обучения - дерево решений CART, параметрами будут правила расщепления (предиктор расщепления и расщепляющее значение).\n",
    "\n",
    "Обратите внимание, что для моделей помимо понятия «параметр» есть понятие «гиперпараметр». Параметры мы находим в ходе обучения модели. А вот гиперпараметры нельзя «выучить» в процессе обучения, их задают перед обучением модели и настраивают на отложенной выборке. \n",
    "\n",
    "Модель импутации не может самостоятельно выяснить оптимальную стратегию импутации. Поэтому стратегия импутации - это гиперпараметр модели, который позволяет улучшить качество модели и настраивается на отложенной выборке (для этого у класса SimpleImputer есть гиперпараметр strategy). \n",
    "\n",
    "Логистическая регрессия не может самостоятельно выяснить оптимальное значение силы регуляризации. Поэтому сила регуляризации - это гиперпараметр модели, который позволяет улучшить качество модели и настраивается на отложенной выборке (для этого у класса LoisticRegression есть гиперпараметр C). \n",
    "\n",
    "Дерево решений CART не может самостоятельно выяснить оптимальное значение максимальной глубины. Поэтому максимальная глубина — это тоже гиперпараметр, который мы настраиваем на отложенной выборке (для этого у класса\n",
    "DecisionTreeClassifier, строящего дерево CART, есть гиперпараметр max_depth).\n",
    "\n",
    "После обучения модели на предыдущем шаге возникает закономерный вопрос: а насколько «хорошо» качество полученной модели? И вот теперь наступает время использовать независимую тестовую выборку. Поскольку модель еще «не видела» эти тестовые данные, такой шаг даст относительно надежную и несмещенную оценку качества на новых, незнакомых данных. \n",
    "\n",
    "Теперь мы берем тестовую выборку и используем модель для прогнозирования меток классов зависимой переменной по наблюдениям. Затем мы берем спрогнозированные метки классов и сравниваем их с фактическими метками классов для оценки обобщающей способности (здесь мы можем использовать правильность — долю правильно спрогнозированных наблюдений от общего количества наблюдений или ошибку классификации). \n",
    "\n",
    "Однако есть сложности. Когда мы строим модели с разными значениями гиперпараметров на обучающей выборке, а проверяем их качество на тестовой выборке, возникает проблема. Мы используем тестовую выборку и для настройки гиперпараметров и для оценки качества модели. Поскольку мы использовали тестовую выборку для настройки гиперпараметров, мы больше не можем использовать ее для оценки качества модели. Это та же самая\n",
    "причина, по которой нам изначально нужно разбивать данные на обучающую и тестовую выборки. \n",
    "\n",
    "Теперь для оценки качества модели нам необходим независимый набор данных, то есть набор, который не использовался для построения модели и настройки ее гиперпараметров и применяется лишь однократно для оценки качества модели. Помним, что тестовая выборка — прообраз новых данных, о которых мы ничего не знаем. \n",
    "\n",
    "В противном случае мы просто будем настраивать нашу модель под тестовую выборку, ведь любой выбор, сделанный, исходя из метрики на тестовом наборе, «сливает» модели информацию тестового набора. В итоге мы можем получить оптимистичные результаты.\n",
    "\n",
    "Для простоты пока пренебрежем этим недостатком случайного разбиения на обучающую и тестовую выборки, поскольку наша задача построить базовую модель машинного обучения, не прибегая к оптимизации гиперпараметров. Такое часто бывает, когда, например, дана задача классификации и нужно сопоставить качество нескольких алгоритмов, строят базовые модели логистической регрессии, случайного леса и градиентного бустинга и сравнивают.\n",
    "\n",
    "Итак, мы получили оценку качества модели на тестовых данных. Таким образом, уже нет смысла резервировать тестовую выборку. Если качество нас устраивает, мы обучаем модель на всех доступных данных и применяем модель, обученную на всех доступных данных, к новым данным.\n",
    "\n",
    "Давайте сделаем случайное разбиение данных на обучающую и тестовую выборки: сформируем обучающий массив признаков, тестовый массив признаков, обучающий массив меток, тестовый массив меток. Это можно будет сделать с помощью функции train_test_split() модуля model_selection библиотеки scikit-learn. В\n",
    "scikit-learn для массива данных обычно используется заглавная X, а для массива меток - строчная y.\n",
    "\n",
    "```python\n",
    "# импортируем функцию train_test_split(), с помощью\n",
    "# которой разбиваем данные на обучающие и тестовые\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# разбиваем данны на обучающие и тестовые\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop['Response', axis=1], # 1\n",
    "    data['Response'], # 2\n",
    "    test_size=0.3, # 3\n",
    "    stratify=data['Response'], # 4\n",
    "    random_state=42 # 5\n",
    ")\n",
    "```\n",
    "\n",
    "- 1. Указываем массив признаков\n",
    "- 2. Указываем зависимую переменную (таргет)\n",
    "- 3. Настраиваем размер тестовой выборки (в процентах)\n",
    "- 4. Стратифицированное ли разбиение?\n",
    "- 5. Так как разбиение случайно, то этот параметр позволяет воспроизводить результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.1 Running linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В самом начале мы исследовали датасет с автомобилем. И мы помним, что в одном из признаков были пропущенные значения. Давайте их удалим. \n",
    "Также обратим внимание, что признак name задан в виде текста. Модель умеет работать только с цифрами, поэтому в данной модели давайте также удалим этот признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сводная информация по пропущенным значениям\n",
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление столбца name\n",
    "df1 = df1.drop('name', axis=1)\n",
    "\n",
    "# удаление всех строк, содержащих хоть одну пропущенную ячейку\n",
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сводная информация по пропущенным значениям\n",
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы знаем, зачем делить выборку на несколько частей. Давайте разделим ее. В качестве целевой переменной будет выступать столбец mpg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'mpg'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df1.drop(target_variable, axis=1), \n",
    "    df1[target_variable], \n",
    "    test_size = 0.2, \n",
    "    random_state=0)\n",
    "\n",
    "print(f'Sanity check for dimensions of variables: {X_train.shape, X_test.shape, y_train.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = sm.OLS(y_train, X_train)     # training on train observations\n",
    "fmdl = mdl.fit()\n",
    "print(fmdl.summary(title='Baseline model for Auto dataset', alpha=.01))\n",
    "\n",
    "y_pred = fmdl.predict(X_test)   # predicted values on the testing set\n",
    "print(f'\\nOut of sample R^2 is {r2_score(y_test, y_pred):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Краткая сводка по функциям измерения ошибки в задачах регрссии: \n",
    "$$MSE(a, X) =  \\frac{1}{l}\\sum_{i=0}^l (a(x_i) - y_i)^2$$\n",
    "$$RMSE =  \\sqrt{MSE(a, X)}$$\n",
    "$$R^2(a, X) =  1 - \\frac{\\sum_{i=0}^l (a(x_i) - y_i)^2}{\\sum_{i=0}^l (y_i - \\bar y)^2}$$\n",
    "\n",
    "$R^2(a, X)$ - коэффициент детеринации. По сути - нормированный MSE. Чем ближе к 1, тем лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2 Improving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'mpg'\n",
    "columns_to_drop = [target_variable]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df1.drop(columns_to_drop, axis=1), \n",
    "    df1[target_variable], \n",
    "    test_size = 0.2, \n",
    "    random_state=0)\n",
    "\n",
    "print(f'Sanity check for dimensions of variables: {X_train.shape, X_test.shape, y_train.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.add_constant(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = sm.OLS(y_train, sm.add_constant(X_train))     # training on train observations\n",
    "fmdl = mdl.fit()\n",
    "print(fmdl.summary(title='Second iteration for Auto dataset', alpha=.01))\n",
    "\n",
    "y_pred = fmdl.predict(sm.add_constant(X_test))   # predicted values on the testing set\n",
    "print(f'\\nOut of sample R^2 is {r2_score(y_test, y_pred):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.3 Linear regression by hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=10000, precision=4, edgeitems=20, suppress=True)\n",
    "\n",
    "# Add the column of ones\n",
    "X_plus_ones = np.column_stack((X_train, np.ones(X_train.shape[0])))\n",
    "X_plus_ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plus_ones[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\textbf{w} = \\left(\\textbf{X}^{\\text{T}} \\textbf{X}\\right)^{-1} \\textbf{X}^{\\text{T}} \\textbf{y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_analytical = np.matmul(np.matmul(np.linalg.inv(np.matmul(X_plus_ones.T, X_plus_ones)), \n",
    "                                              X_plus_ones.T), \n",
    "                                    y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_analytical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если сравнить данные коэффициенты с коэффициентами предыдущей модели, то мы увидим 100% попадание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод ближайших соседей\n",
    "\n",
    "Метод ближайших соседей (k Nearest Neighbors, или kNN) — тоже очень популярный метод классификации, также иногда используемый в задачах регрессии. Это, наравне с деревом решений, один из самых понятных подходов к классификации. На уровне интуиции суть метода такова: посмотри на соседей, какие преобладают, таков и ты. Формально основой метода является гипотезой компактности: если метрика расстояния между примерами введена достаточно удачно, то схожие примеры гораздо чаще лежат в одном классе, чем в разных. \n",
    "\n",
    "Например, если не знаешь, какой тип товара указать в объявлении для Bluetooth-гарнитуры, можешь найти 5 похожих гарнитур, и если 4 из них отнесены к категории \"Аксессуары\", и только один - к категории \"Техника\", то здравый смысл подскажет для своего объявления тоже указать категорию \"Аксессуары\".\n",
    "\n",
    "Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить следующие операции:\n",
    " - Вычислить расстояние до каждого из объектов обучающей выборки\n",
    " - Отобрать $k$ объектов обучающей выборки, расстояние до которых минимально\n",
    " - Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди $k$ ближайших соседей\n",
    " \n",
    " Примечательное свойство такого подхода  – его ленивость. Это значит, что вычисления начинаются только в момент классификации тестового примера, а заранее, только при  наличии обучающих примеров, никакая модель не строится. В этом отличие, например, от ранее рассмотренного дерева решений, где сначала на основе обучающей выборки строится дерево, а потом относительно быстро происходит классификация тестовых примеров. \n",
    " \n",
    "Стоит отметить, что метод ближайших соседей – хорошо изученный подход (в машинном обучении, эконометрике и статистике больше известно наверно только про линейную регрессию). Для метода ближайших соседей существует немало важных теорем, утверждающих, что на \"бесконечных\" выборках это оптимальный метод классификации. Авторы классической книги \"The Elements of Statistical Learning\" считают kNN теоретически идеальным алгоритмом, применимость которого просто ограничена вычислительными возможностями и проклятием размерностей. \n",
    "\n",
    "### Метод ближайших соседей в реальных задачах\n",
    "- В чистом виде kNN может послужить хорошим стартом (baseline) в решении какой-либо задачи;\n",
    "- В соревнованиях Kaggle kNN часто используется для построения мета-признаков (прогноз kNN подается на вход прочим моделям) или в стекинге/блендинге;\n",
    "- Идея ближайшего соседа расширяется и на другие задачи, например, в рекомендательных системах простым начальным решением может быть рекомендация какого-то товара (или услуги), популярного среди *ближайших соседей* человека, которому хотим сделать рекомендацию;\n",
    "- На практике для больших выборок часто пользуются *приближенными* методами поиска ближайших соседей. [Вот](https://www.youtube.com/watch?v=UUm4MOyVTnE) лекция Артема Бабенко про эффективные алгоритмы поиска ближайших соседей среди миллиардов объектов в пространствах высокой размерности (поиск по картинкам). Также известны открытые библиотеки, в которых реализованы такие алгоритмы, спасибо компании Spotify за ее библиотеку [Annoy](https://github.com/spotify/annoy).\n",
    "\n",
    "Качество классификации методом ближайших соседей зависит от нескольких параметров:\n",
    " - число соседей\n",
    " - метрика расстояния между объектами (часто используются метрика Хэмминга, евклидово расстояние, косинусное расстояние и расстояние Минковского). Отметим, что при использовании большинства метрик значения признаков надо масштабировать. Условно говоря, чтобы признак \"Зарплата\" с диапазоном значений до 100 тысяч не вносил больший вклад в расстояние, чем \"Возраст\" со значениями до 100. \n",
    " - веса соседей (соседи тестового примера могут входить с разными весами, например, чем дальше пример, тем с меньшим коэффициентом учитывается его \"голос\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.1 Run kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'mpg'\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df1.drop(target_variable, axis=1), \n",
    "    df1[target_variable], \n",
    "    test_size = 0.2, random_state=0)\n",
    "\n",
    "print(f'Sanity check for dimensions of variables: {X_train.shape, X_test.shape, y_train.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс KNeighborsClassifier в Scikit-learn\n",
    "Основные параметры класса sklearn.neighbors.KNeighborsClassifier:\n",
    " - weights: \"uniform\" (все веса равны), \"distance\" (вес обратно пропорционален расстоянию до тестового примера) или другая определенная пользователем функция\n",
    " - algorithm (опционально): \"brute\", \"ball_tree\", \"KD_tree\", или \"auto\". В первом случае ближайшие соседи для каждого тестового примера считаются перебором обучающей выборки. Во втором и третьем - расстояние между примерами хранятся в дереве, что ускоряет нахождение ближайших соседей. В случае указания параметра \"auto\" подходящий способ нахождения соседей будет выбран автоматически на основе обучающей выборки.\n",
    " - leaf_size (опционально): порог переключения на полный перебор в случае выбора BallTree или KDTree для нахождения соседей\n",
    " - metric: \"minkowski\", \"manhattan\", \"euclidean\", \"chebyshev\" и другие"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=5, \n",
    "    weights='uniform')\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)   # predicted values on the testing set\n",
    "print(f'\\nOut of sample R^2 is {r2_score(y_test, y_pred):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.2 Scale the data and rerun it\n",
    "Данный алгоритм очень чувстсвителен к масштабу данных (на самом делее, как и любая регрессия)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте воспользуемся классом StandardScaler, строящим модель стандартизации. Самая простая стандартизация подразумевает, что из каждого значения переменной мы вычтем среднее значение и полученный результат разделим на стандартное отклонение (в случае присутствия бинарных переменных для улучшения интерпретируемости делят на два стандартных отклонения).\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler(\n",
    "    copy=True, # 1\n",
    "    with_mean=True, # 2\n",
    "    with_std=True # 3\n",
    ")\n",
    "```\n",
    "- 1. Если задано False, пробует избежать копирования и вместо этого выполняет стандартизацию на месте. Стандартизация на месте не всегда гарантируется. Например, если данные не являются массивом NumPy или CSR матрицей из модуля scipy.sparse, все равно может быть возвращена копия.\n",
    "- 2. Центрирует данные (вычитает из исходного значения переменной среднее значение) перед тем, как поделить на стандартное отклонение.\n",
    "- 3. Делит на стандартное отклонение.\n",
    "\n",
    "Стандартизация необходима для некоторых методов машинного обучения, в частности, для линейной и логистической регрессий. Она приводит количественные независимые переменные к единому масштабу. Если не привести признаки к единому масштабу, то прогноз будут определять признаки, имеющие наибольший разряд и соответственно наибольшую дисперсию. \n",
    "\n",
    "Различный масштаб признаков приведет к ухудшению сходимости в случае применения градиентного спуска (его используют для оценивания регрессионных коэффициентов). Кроме того, единый масштаб позволит нам сравнивать регрессионные коэффициенты при предикторах между собой. \n",
    "\n",
    "В нашем наборе только количественные признаки, если бы здесь были категориальные признаки, мы обязательно превратили бы их в количественные с помощью дамми-кодирования (регрессионные модели работают только с количественными признаками и для моделирования мы используем массивы NumPy, каждый столбец которого должен быть количественным признаком, датафреймы pandas внутренне преобразовываются в массивы NumPy). \n",
    "\n",
    "У нас каждый уровень категориальной переменной стал бы отдельным бинарным столбцом\n",
    "со значениями 0 или 1 и такие переменные не нужно стандартизировать.\n",
    "\n",
    "Мы импортируем класс StandardScaler и создаем его экземпляр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "\n",
    "standardized_X = scaler.transform(X_train)\n",
    "standardized_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=5, \n",
    "    weights='uniform')\n",
    "\n",
    "knn.fit(standardized_X, y_train)\n",
    "y_pred = knn.predict(standardized_X_test)   # predicted values on the testing set\n",
    "print(f'\\nOut of sample R^2 is {r2_score(y_test, y_pred):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.3 Comparison between kNN and LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = 3\n",
    "\n",
    "var_name = X_train.columns[x_var]\n",
    "xx_train = X_train.iloc[:, x_var].values.reshape(-1, 1)\n",
    "xx_test = X_test.iloc[:, x_var].values.reshape(-1, 1)\n",
    "\n",
    "x_grid = np.linspace(xx_train.min(), xx_train.max(), 100).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 50\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(xx_train, y_train, color='darkorange', label='data')\n",
    "\n",
    "# knn prediction\n",
    "knn = KNeighborsRegressor(n_neighbors, weights='uniform')\n",
    "knn.fit(xx_train, y_train.values)\n",
    "y_grid = knn.predict(x_grid)\n",
    "plt.plot(x_grid, y_grid, color='navy', label='knn', linewidth=3)\n",
    "\n",
    "# linear regression prediction\n",
    "mdl = sm.OLS(y_train.values, sm.add_constant(xx_train)).fit()    # training on train observations\n",
    "y_grid = mdl.predict(sm.add_constant(x_grid))   # predicted values on the testing set\n",
    "plt.plot(x_grid, y_grid, color='green', label='linear regression', linewidth=3);\n",
    "\n",
    "plt.ylabel(target_variable)\n",
    "plt.xlabel(var_name);\n",
    "plt.axis('tight');\n",
    "plt.legend();\n",
    "\n",
    "plt.grid()\n",
    "plt.tight_layout();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.4 Fitting kNN for different k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравним разное количество ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 'uniform'\n",
    "\n",
    "plt.figure(figsize=(10, 14))\n",
    "\n",
    "for i, n_neighbors in enumerate([1, 3, 10, 20]):\n",
    "    knn = KNeighborsRegressor(n_neighbors, weights=weights)\n",
    "    knn.fit(xx_train, y_train.values)\n",
    "    \n",
    "    y_grid = knn.predict(x_grid)\n",
    "\n",
    "    plt.subplot(4, 1, i + 1);\n",
    "    plt.scatter(xx_train, y_train, color='darkorange', label='data');\n",
    "    plt.plot(x_grid, y_grid, color='navy', label='prediction');\n",
    "    plt.axis('tight');\n",
    "    plt.ylabel(target_variable)\n",
    "    plt.xlabel(var_name);\n",
    "    plt.legend();\n",
    "    plt.grid()\n",
    "    plt.title(\"KNeighborsRegressor (k = %i, weights = '%s')\" % (n_neighbors, weights));\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравним разные настройки весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 15\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for i, weights in enumerate(['uniform', 'distance']):\n",
    "    knn = KNeighborsRegressor(n_neighbors, weights=weights)\n",
    "    knn.fit(xx_train, y_train.values)\n",
    "    \n",
    "    y_grid = knn.predict(x_grid)\n",
    "\n",
    "    plt.subplot(2, 1, i + 1);\n",
    "    plt.scatter(xx_train, y_train, color='darkorange', label='data');\n",
    "    plt.plot(x_grid, y_grid, color='navy', label='prediction');\n",
    "    plt.axis('tight');\n",
    "    plt.ylabel(target_variable)\n",
    "    plt.xlabel(var_name);\n",
    "    plt.legend();\n",
    "    plt.grid()\n",
    "    plt.title(\"KNeighborsRegressor (k = %i, weights = '%s')\" % (n_neighbors, weights));\n",
    "\n",
    "plt.tight_layout();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кросс-валидация - продвинутый метод оценки моделей\n",
    "\n",
    "Ранее мы говорили о таком простом способе проверки модели, как случайное разбиение на обучающую и тестовую выборки. \n",
    "\n",
    "Еще одним методом проверки является К-блочная перекрестная проверка. Метод К-блочной\n",
    "перекрестной проверки (ее еще называют кросс-валидацией) разбивает весь набор данных на К блоков (обычно 5 или 10) приблизительно равного объема, а затем К раз на К-1 блоках осуществляет обучение модели (эти блоки называют обучающими, по сути они формируют обучающую выборку), а блок, не участвовавший в обучении, использует для проверки (этот блок называют тестовым блоком, по сути он является тестовой выборкой, однако если перекрестная проверка используется внутри комбинированной проверки для настройки гиперпараметров и выбора оптимальной модели, блок называют проверочным блоком или проверочной выборкой).\n",
    "\n",
    "Проще говоря, для набора данных, разбитого на 5 блоков, будет построено 5 моделей, первая модель обучается по всем данным, за исключением данных из первого блока,\n",
    "вторая модель обучается по всем данным, за  исключением данных из второго блока и т.д.\n",
    "\n",
    "Качество модели проверяется путем применения модели, построенной по обучающим блокам, к тестовому блоку, исключенного из процесса построения данной модели. Затем метрики качества, вычисленные по каждому тестовому блоку, усредняют и получают итоговую метрику качества модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отметим основную разницу между методом разбиения на обучающую и тестовую выборки и К-блочной перекрестной проверкой: в К-блочной перекрестной проверке для обучения и проверки используются все доступные данные. \n",
    "\n",
    "Идея, лежащая в основе этого метода, состоит в уменьшении пессимистичного смещения за счет использования большего количества данных для обучения вместо того, чтобы отложить\n",
    "в качестве тестовой выборки довольно большую часть набора.\n",
    "\n",
    "Для выполнения перекрестной проверки мы можем воспользоваться функцией cross_val_score().\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score(\n",
    "    estimator, # 1\n",
    "    X, # 2\n",
    "    y=None, # 3\n",
    "    scoring=None, # 4\n",
    "    cv='warn', # 5\n",
    "    n_jobs=None # 6\n",
    ")\n",
    "```\n",
    "\n",
    "- 1 - Модель, используемая для обучения\n",
    "- 2 - Массив признаков\n",
    "- 3 - Массив меток\n",
    "- 4 - Метрика, оцениваемая в ходе перекрестной проверки\n",
    "- 5 - Стратегия перекрестной проверки. Возможные значения:\n",
    "    - None, будет использована 5-блочная перекрестная проверка\n",
    "    - целочисленное значение, задает количество блоков для (Stratified)Kfold\n",
    "\n",
    "    Для None и целочисленных значений, если модель является классификатором и y является либо бинарной, либо мультиклассовой переменной, используется StratifiedKfold. Во всех остальных случаях используется Kfold.\n",
    "- 6 - Количество используемых ядер процессора для распараллеливания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя функцию cross_val_predict(), мы в каждой итерации перекрестной проверки с помощью модели, обученной на обучающих блоках, можем получить спрогнозированные значения/спрогнозированные вероятности для наблюдений каждого тестового блока, затем эти спрогнозированные значения/спрогнозированные вероятности конкатенируются и мы получаем спрогнозированные значения/спрогнозированные вероятности для всего набора в отсортированном порядке.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_predict(\n",
    "    estimator, # 1\n",
    "    X, # 2\n",
    "    y=None, # 3\n",
    "    groups=None, # 4\n",
    "    n_jobs=None, # 5\n",
    "    method='predict', # /'predict_proba'   6\n",
    "    cv=None # 7\n",
    ")\n",
    "```\n",
    "\n",
    "- 1 - Модель, используемая для обучения\n",
    "- 2 - Массив признаков\n",
    "- 3 - Массив меток\n",
    "- 4 - Массив вида (n_samples,), содержащий метки группы для наблюдений, определяемых в обучающую/тестовую выборки (например, GroupKFold)\n",
    "- 5 - Количество используемых ядер процессора для распараллеливания\n",
    "- 6 - Вывод спрогнозированных значений или спрогнозированных вероятностей\n",
    "- 7 - Стратегия перекрестной проверки. Возможные значения:\n",
    "    - None, будет использована 5-блочная перекрестная проверка\n",
    "    - целочисленное значение, задает количество блоков для (Stratified)Kfold\n",
    "\n",
    "    Для None и целочисленных значений, если модель является классификатором и y является либо бинарной, либо мультиклассовой переменной, используется StratifiedKfold. Во всех остальных случаях используется Kfold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
